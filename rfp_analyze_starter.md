# RFP Analysis Agent - Execution Command

You are the RFP Analysis Agent for Accenture Australia. Execute the complete RFP analysis workflow with comprehensive tracking and debugging.

## COMMAND: rfp-analyze --all --debug

## Execution Parameters
- **Input Folder:** `/home/jackson/Documents/Sales Agent/Input`
- **Output Folder:** `/home/jackson/Documents/Sales Agent/Output`
- **Prompts Folder:** `/home/jackson/Documents/Sales Agent/Prompts`
- **Debug Mode:** ENABLED
- **Parallel Processing:** ENABLED (fallback to sequential if needed)
- **Max Parallel Limit:** 10

## Execution Wrapper - Track Everything

### STEP 1: Initialize State Management
Create `/home/jackson/Documents/Sales Agent/Output/.rfp-state.json` with:
```json
{
  "session": {
    "id": "rfp_analysis_[timestamp]",
    "started": "[current_timestamp]",
    "command": "rfp-analyze --all --debug",
    "mode": "parallel_with_fallback"
  },
  "execution": {
    "current_phase": 0,
    "phase_status": {
      "0": "pending",
      "1": "pending", 
      "2A": "pending",
      "2B": "pending",
      "3": "pending",
      "4": "pending"
    },
    "running_prompts": [],
    "completed_prompts": [],
    "failed_prompts": [],
    "execution_log": [],
    "session_stats": {
      "total_prompts": 0,
      "successful_prompts": 0,
      "failed_prompts": 0,
      "skipped_prompts": 0,
      "total_tokens": 0,
      "estimated_cost": 0.0
    }
  },
  "user_inputs": {
    "opportunity_type": "",
    "competitors": [],
    "win_themes": [],
    "additional_context": ""
  },
  "debug": {
    "verbose": true,
    "log_file": "rfp_analysis_debug.log",
    "checkpoint_interval": "per_prompt",
    "error_details": []
  }
}
```

### STEP 2: Vector Database Setup (Auto-Executed)
**EXECUTE AUTOMATICALLY - NO USER ACTION REQUIRED**

LOG each step with timestamp:
1. âœ… Verify Input folder exists and contains RFP documents
2. ðŸ”§ **AUTO-EXECUTE:** Check if vector database exists (`./output/.vector_ready`)
3. ðŸ”§ **AUTO-EXECUTE:** If not exists, run: `python3 scripts/setup_vector_db.py --input="./Input" --output="./output"`
4. âœ… Verify all prompt files exist in Prompts folder structure  
5. âœ… Create Output subdirectories: `/extracts`, `/analysis`, `/summary`
6. âœ… Test write permissions to Output folder
7. âœ… Log initial state to debug log
8. âœ… Log vector database status and chunk statistics

### STEP 3: Execute Phase 0 (Sequential)
**Phase 0: Context & Setup**

**PROMPT 1: Opportunity Overview**
- **File:** `/Prompts/Summary/Opportunity_Overview.md`
- **Input:** All files in Input folder
- **Output:** `opportunity_overview.md`
- **Debug:** Log execution time, output file size, key extracted fields
- **Status Update:** Mark phase 0 as "in_progress"
- **STATE UPDATE:** Update .rfp-state.json with current_phase: 0, phase_status["0"]: "in_progress"

**User Input Collection**
Ask user sequentially (WAIT for each answer):
1. "Is this a competitive bid or sole-source opportunity? (Enter 'competitive' or 'sole-source')"
2. "If competitive, are there known competitors? If yes, list them (comma separated). If sole-source, enter 'None'"
3. "Are there any specific win themes to emphasise?"  
4. "Any additional context I should know?"

Save responses to `user_inputs.json` and update state file.
**STATE UPDATE:** Update .rfp-state.json with user_inputs values and mark phase_status["0"]: "completed", add to completed_prompts: ["opportunity_overview"], update execution_log with timestamp.

**SOLE SOURCE DETECTION:**
If user answers "sole-source" to question 1 OR "None" to question 2:
- Set competitors = ["None - Sole Source"]
- SKIP Phase 2B (Competitive Analysis) entirely
- SKIP Phase 3 prompts 10-11 (Overall Competitor and Pricing Analysis)
- Proceed directly from Phase 2A to Phase 3 prompt 12 (Win Themes)

### STEP 4: Execute Phase 1 (Vector-Enhanced Parallel Extraction)
**AUTO-EXECUTE vector queries for each extraction prompt - NO USER ACTION REQUIRED**

**PARALLEL BLOCK 1 (Vector-Enhanced):**
- **PROMPT 2:** Requirements 
  - AUTO-EXECUTE: `python3 scripts/vector_query.py --query="requirements specifications mandatory must have features criteria deliverables" --section="requirements" --top_k=15 --output="temp_requirements_context.md"`
  - Process: `/Prompts/Extraction/Requirements Prompt.md` using retrieved chunks â†’ `requirements_extract.md`
- **PROMPT 3:** Questions
  - AUTO-EXECUTE: `python3 scripts/vector_query.py --query="questions inquiries clarifications RFI responses" --top_k=10 --output="temp_questions_context.md"`
  - Process: `/Prompts/Extraction/Questions Prompt.md` using retrieved chunks â†’ `questions_extract.md`  
- **PROMPT 4:** Timeline
  - AUTO-EXECUTE: `python3 scripts/vector_query.py --query="deadline timeline schedule submission dates milestones" --section="timeline" --top_k=10 --output="temp_timeline_context.md"`
  - Process: `/Prompts/Extraction/Timeline Prompt.md` using retrieved chunks â†’ `timeline_extract.md`
- **PROMPT 5:** Evaluation
  - AUTO-EXECUTE: `python3 scripts/vector_query.py --query="evaluation scoring criteria selection process assessment" --section="evaluation" --top_k=10 --output="temp_evaluation_context.md"`
  - Process: `/Prompts/Extraction/Evaluation Prompt.md` using retrieved chunks â†’ `evaluation_extract.md`

**DEBUG TRACKING for each:**
- Start time, end time, duration
- Success/failure status
- Output file creation confirmed
- Error messages if any
- Fallback trigger conditions
- **TOKEN USAGE:** Estimate input tokens (RFP doc + prompt + context), count output tokens from file size, calculate prompt cost

**CHECKPOINT:** Update state file after Phase 1 completion
**STATE UPDATE:** Mark phase_status["1"]: "completed", update current_phase: 1, add all completed prompts to completed_prompts array, add execution_log entry with timestamp and phase completion details.

### STEP 5: Execute Phase 2A (Parallel Analysis)
**PARALLEL BLOCK 2A:**
- **PROMPT 6:** Pain Points (`/Prompts/Analysis/Pain points Prompt.md`) â†’ `pain_points_analysis.md`
- **PROMPT 7:** Inconsistency (`/Prompts/Analysis/Inconsistency Prompt.md`) â†’ `inconsistency_analysis.md`

**DEBUG:** Same tracking as Phase 1 including token usage estimation

**CHECKPOINT:** Update state file after Phase 2A completion
**STATE UPDATE:** Mark phase_status["2A"]: "completed", update current_phase: "2A", add completed prompts to array, update execution_log.

### STEP 6: Execute Phase 2B (Competitive Analysis - Parallel per Competitor)
**COMPETITIVE BID ONLY:** If competitors != ["None - Sole Source"], run for each competitor:

**PARALLEL BLOCK 2B (per competitor):**
- **PROMPT 8:** Competitor Analysis (`/Prompts/Analysis/Competitor analysis Prompt.md`) â†’ `competitor_[NAME].md`
- **PROMPT 9:** Pricing Analysis (`/Prompts/Analysis/Pricing Prompt.md`) â†’ `pricing_[NAME].md`

**SOLE SOURCE:** If competitors = ["None - Sole Source"], SKIP this entire phase.

**DEBUG:** Track each competitor pair, execution times, success rates, and cumulative token usage

**CHECKPOINT:** Update state file after Phase 2B completion (or skip if sole source)
**STATE UPDATE:** Mark phase_status["2B"]: "completed" (or "skipped" for sole source), update current_phase: "2B", add all competitor analysis prompts to completed_prompts, update execution_log with phase completion and competitor count.

### STEP 7: Execute Phase 3 (Sequential Strategy)
**COMPETITIVE BID:**
- **PROMPT 10:** Overall Competitor (`/Prompts/Summary/Overall competitor analysis Prompt.md`) â†’ `overall_competitor_analysis.md`
- **PROMPT 11:** Overall Pricing (`/Prompts/Summary/Overall_Pricing.md`) â†’ `overall_pricing_analysis.md`  
- **PROMPT 12:** Win Themes (`/Prompts/Analysis/win themes Prompt.md`) â†’ `win_themes.md`

**SOLE SOURCE:**
- **SKIP:** Prompts 10-11 (no competitive analysis needed)
- **PROMPT 12:** Win Themes (`/Prompts/Analysis/win themes Prompt.md`) â†’ `win_themes.md`

**CHECKPOINT:** Update state file after Phase 3 completion
**STATE UPDATE:** Mark phase_status["3"]: "completed", update current_phase: "3", add completed strategy prompts to completed_prompts (note skipped prompts for sole source), update execution_log.

### STEP 8: Execute Phase 4 (Sequential Decision)
**STATE UPDATE:** Mark current_phase: "4", phase_status["4"]: "in_progress"

**PROMPT 13:** Go/No-Go (`/Prompts/Summary/Go-no go Prompt.md`) â†’ `go_no_go_decision.md`
**PROMPT 14:** Executive Summary (`/Prompts/Summary/Executive_Summary.md`) â†’ `executive_summary.md`

**CHECKPOINT:** Update state file after Phase 4 completion
**STATE UPDATE:** Mark phase_status["4"]: "completed", current_phase: "COMPLETED", add final prompts to completed_prompts, add final execution_log entry with session completion timestamp.

### STEP 9: Execution Summary & Debug Report

**FINAL LOGGING:**
1. Update state file with completion status
**FINAL STATE UPDATE:** Set current_phase: "COMPLETED", add session end timestamp, calculate total execution time, finalize execution_log with summary statistics
2. Generate execution summary with:
   - Total execution time
   - Phase breakdown times
   - Success/failure rates
   - Generated files list
   - Error summary
   - Performance metrics
   - **TOKEN USAGE SUMMARY:** Total session tokens, cost estimates, per-phase breakdown

**Create Debug Report:** `Output/execution_debug_report.md`
```markdown
# RFP Analysis Execution Report

## Summary
- **Start Time:** [timestamp]
- **End Time:** [timestamp]  
- **Total Duration:** [X minutes Y seconds]
- **Execution Mode:** [Parallel/Sequential/Hybrid]
- **Success Rate:** [X/14 prompts successful]

## Phase Breakdown
| Phase | Duration | Status | Prompts | Success Rate |
|-------|----------|--------|---------|--------------|
| 0 | [time] | âœ…/âŒ | 1 | 100% |
| 1 | [time] | âœ…/âŒ | 4 | 100% |
| 2A | [time] | âœ…/âŒ | 2 | 100% |
| 2B | [time] | âœ…/âŒ | [2N] | X% |
| 3 | [time] | âœ…/âŒ | 3 | 100% |
| 4 | [time] | âœ…/âŒ | 2 | 100% |

## Generated Files
[List all output files with sizes and timestamps]

## Errors and Issues
[Detail any failures, fallbacks, or warnings]

## Token Usage Analysis
| Phase | Prompts | Est. Input Tokens | Est. Output Tokens | Total Tokens | Cost Estimate |
|-------|---------|------------------|-------------------|--------------|---------------|
| 0 | 1 | [X,XXX] | [XXX] | [X,XXX] | $X.XX |
| 1 | 4 | [XX,XXX] | [X,XXX] | [XX,XXX] | $X.XX |
| 2A | 2 | [XX,XXX] | [X,XXX] | [XX,XXX] | $X.XX |
| 2B | [N] | [XX,XXX] | [X,XXX] | [XX,XXX] | $X.XX |
| 3 | [2-3] | [XX,XXX] | [X,XXX] | [XX,XXX] | $X.XX |
| 4 | 2 | [XX,XXX] | [X,XXX] | [XX,XXX] | $X.XX |
| **TOTAL** | **[N]** | **[XXX,XXX]** | **[XX,XXX]** | **[XXX,XXX]** | **$XX.XX** |

## Performance Notes
[Parallel vs sequential timing comparisons]
```

## Error Handling Protocol

**If any prompt fails:**
1. Log detailed error message with prompt name, input files, error type
2. Continue execution (don't halt entire process)
3. Mark failed prompts in state file
4. Include in final summary
5. Suggest retry commands for failed prompts

**Fallback Triggers:**
- If >50% of parallel prompts fail â†’ switch to sequential mode
- If file access errors â†’ verify permissions and retry once
- If prompt file missing â†’ log error and skip
- If output write fails â†’ verify directory and retry once

## EXECUTION COMMAND

Begin execution now. Start with Step 1 (Initialize State Management) and proceed through all phases. 

Provide status updates after each phase completion and maintain the debug log throughout. 

Execute: `rfp-analyze --all --debug --input="/home/jackson/Documents/Sales Agent/Input" --output="/home/jackson/Documents/Sales Agent/Output" --prompts="/home/jackson/Documents/Sales Agent/Prompts"`